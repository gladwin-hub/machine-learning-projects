# -*- coding: utf-8 -*-
"""cat_vs_dog_classification_using_transfer_learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MR3CJxg3vHqE-z6q7DFpznMg2lh8KNia
"""

!pip install kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c dogs-vs-cats

from zipfile import ZipFile
file_name='/content/dogs-vs-cats.zip'
with ZipFile(file_name, 'r') as zip:
  zip.extractall()

from zipfile import ZipFile
file_name='/content/train.zip'
with ZipFile(file_name, 'r') as zip:
  zip.extractall()

from zipfile import ZipFile
file_name='/content/test1.zip'
with ZipFile(file_name, 'r') as zip:
  zip.extractall()

import os
file=os.listdir('/content/train')
print(file)

file=os.listdir('/content/train')
dog_count=0
cat_count=0
for i in file:
  name=i[0:3]
  if name=='dog':
    dog_count+=1
  else:
    cat_count+=1
print('dog_count:', dog_count)
print('cat_count:', cat_count)

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as impg
from PIL import Image
from sklearn.model_selection import train_test_split
from google.colab.patches import cv2_imshow

img=impg.imread('/content/train/dog.2395.jpg')
plot=plt.imshow(img)
plt.show()

img=impg.imread('/content/train/cat.2129.jpg')
plot=plt.imshow(img)
plt.show()

original='/content/train/'
resized='/content/resized/'
for i in range(2000):
  file=os.listdir(original)[i]
  img=original+file
  img=Image.open(img)
  img=img.resize((224,224))
  img=img.convert('RGB')
  newpath=resized+file
  img.save(newpath)

file=os.listdir(resized)
print(file)

img=impg.imread('/content/resized/dog.2395.jpg')
plot=plt.imshow(img)
plt.show()

img=impg.imread('/content/resized/cat.2129.jpg')
plot=plt.imshow(img)
plt.show()

file=os.listdir('/content/train')
labels=[]
for i in range(2000):
  filename=file[i]
  label=filename[0:3]
  if label=='dog':
    labels.append(1)
  else:
    labels.append(0)

print(len(labels))
print(labels[0:4])
values, counts = np.unique(labels, return_counts=True)
print(values)
print(counts)

import cv2
import glob

file='/content/resized/'
dir_extension=['png','jpg']
data=[]

[data.extend(glob.glob(file+'*.'+e)) for e in dir_extension]
images=np.asarray([cv2.imread(files) for files in data])

print(images)

type(images)

print(images.shape)

x=images
y=np.asarray(labels)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)

print(x.shape, x_train.shape, x_test.shape)

x_train=x_train/255
x_test=x_test/255

print(x_train)



!pip install tensorflow==2.15.0 tensorflow-hub
import tensorflow as tf
import tensorflow_hub as hb
mobilenet_model="https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4"
pretrained_model=hb.KerasLayer(mobilenet_model, input_shape=(224,224,3),trainable=False)

model = tf.keras.Sequential([

    pretrained_model,
    tf.keras.layers.Dense(2)

])

model.summary()

model.compile(
    optimizer = 'adam',
    loss = 'SparseCategoricalCrossentropy',
    metrics = ['acc']
)

model.fit(x_train, y_train,validation_split=0.2, epochs=5)

score, acc = model.evaluate(x_test, y_test)
print('Test Loss =', score)
print('Test Accuracy =', acc)

input_image_path = input('path of image to be predicted ')

input_image = cv2.imread(input_image_path)

cv2_imshow(input_image)

input_image_resize = cv2.resize(input_image, (224,224))

input_image_scaled = input_image_resize/255

image_reshaped = np.reshape(input_image_scaled, [1,224,224,3])

input_prediction = model.predict(image_reshaped)

print(input_prediction)

input_pred_label = np.argmax(input_prediction)

print(input_pred_label)

if input_pred_label == 0:
  print('The image represents a Cat')

else:
  print('The image represents a Dog')

